<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xingyi Du&#39;s Homepage</title>
    <link>https://duxingyi-charles.github.io/</link>
      <atom:link href="https://duxingyi-charles.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Xingyi Du&#39;s Homepage</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020</copyright>
    <image>
      <url>https://duxingyi-charles.github.io/img/avatar.jpg</url>
      <title>Xingyi Du&#39;s Homepage</title>
      <link>https://duxingyi-charles.github.io/</link>
    </image>
    
    <item>
      <title>Robust Computation of Implicit Surface Networks for Piecewise Linear Functions</title>
      <link>https://duxingyi-charles.github.io/publication/robust-computation-of-implicit-surface-networks-for-piecewise-linear-functions/</link>
      <pubDate>Thu, 28 Apr 2022 17:23:54 -0500</pubDate>
      <guid>https://duxingyi-charles.github.io/publication/robust-computation-of-implicit-surface-networks-for-piecewise-linear-functions/</guid>
      <description>














&lt;figure id=&#34;figure-figure-1-implicit-surface-networks-such-as-implicit-arrangement-left-obtained-for-primitive-geometry-defining-a-cad-object-and-material-interfaces-right-the-voronoi-diagram-of-rotating-3d-lines-produced-by-our-robust-algorithms-each-example-is-visualized-by-its-surface-patches-non-manifold-curve-network-as-well-as-the-3d-regions-partitioned-by-the-surface-network&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/Implicit_network/fig-teaser.jpg&#34; data-caption=&#34;Figure 1. Implicit surface networks, such as implicit arrangement (left, obtained for primitive geometry defining a CAD object) and material interfaces (right, the Voronoi diagram of rotating 3D lines), produced by our robust algorithms. Each example is visualized by its surface patches, non-manifold curve network as well as the 3D regions partitioned by the surface network.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/Implicit_network/fig-teaser.jpg&#34; alt=&#34;featured&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1. Implicit surface networks, such as implicit arrangement (left, obtained for primitive geometry defining a CAD object) and material interfaces (right, the Voronoi diagram of rotating 3D lines), produced by our robust algorithms. Each example is visualized by its surface patches, non-manifold curve network as well as the 3D regions partitioned by the surface network.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;abstract&#34;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Implicit surface networks, such as arrangements of implicit surfaces and materials interfaces, are used for modeling piecewise smooth or partitioned shapes. However, accurate and numerically robust algorithms for discretizing either structure on a grid are still lacking. We present a unified approach for computing both types of surface networks for piecewise linear functions defined on a tetrahedral grid. Both algorithms are guaranteed to produce a correct combinatorial structure for any number of functions. Our main contribution is an exact and efficient method for partitioning a tetrahedron using the level sets of linear functions defined by barycentric interpolation. To further improve performance, we designed look-up tables to speed up processing of tetrahedra involving few functions and introduced an efficient algorithm for identifying nested 3D regions.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/d8Vl6jZdgmI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;results&#34;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h2&gt;















&lt;figure id=&#34;figure-figure-2-implict-arrangements-computed-by-our-algorithm-on-implicit-functions-representing-cad-models-each-example-shows-the-non-manifold-curve-networks-patches-and-3d-regions-in-exploded-view-complexity-of-each-example-running-time-of-our-method-full-pipeline-and-mesh-arrangement-are-noted&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/Implicit_network/fig-ia-results.jpg&#34; data-caption=&#34;Figure 2. Implict arrangements computed by our algorithm on implicit functions representing CAD models. Each example shows the non-manifold curve networks, patches, and 3D regions (in exploded view). Complexity of each example, running time of our method (full pipeline) and mesh arrangement are noted.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/Implicit_network/fig-ia-results.jpg&#34; alt=&#34;fig-ia-results&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 2. Implict arrangements computed by our algorithm on implicit functions representing CAD models. Each example shows the non-manifold curve networks, patches, and 3D regions (in exploded view). Complexity of each example, running time of our method (full pipeline) and mesh arrangement are noted.
  &lt;/figcaption&gt;


&lt;/figure&gt;
















&lt;figure id=&#34;figure-figure-3-voronoi-diagrams-of-3d-lines-top-left-5-rotating-lines-top-right-20-rotating-lines-bottom-left-21-lines-that-sweep-a-mobius-strip-and-circles-bottom-right-22-villarceau-circles-on-two-tori-computed-by-our-algorithm-and-the-label-separating-algorithm-the-zoom-in-views-highlight-regions-on-the-non-manifold-curve-networks-where-the-two-algorithms-produce-notably-different-geometry-andor-topology-the-combinatorial-complexity-of-each-surface-network-and-the-running-times-up-to-mesh-extraction-before-space-decomposition-are-noted&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/Implicit_network/fig-mi-dc-results.jpg&#34; data-caption=&#34;Figure 3. Voronoi diagrams of 3D lines (top left: 5 rotating lines; top right: 20 rotating lines; bottom left: 21 lines that sweep a Mobius strip) and circles (bottom right: 22 Villarceau circles on two tori) computed by our algorithm and the label-separating algorithm. The zoom-in views highlight regions on the non-manifold curve networks where the two algorithms produce notably different geometry and/or topology. The combinatorial complexity of each surface network and the running times (up to mesh extraction, before space decomposition) are noted.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/Implicit_network/fig-mi-dc-results.jpg&#34; alt=&#34;fig-mi-dc-results&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 3. Voronoi diagrams of 3D lines (top left: 5 rotating lines; top right: 20 rotating lines; bottom left: 21 lines that sweep a Mobius strip) and circles (bottom right: 22 Villarceau circles on two tori) computed by our algorithm and the label-separating algorithm. The zoom-in views highlight regions on the non-manifold curve networks where the two algorithms produce notably different geometry and/or topology. The combinatorial complexity of each surface network and the running times (up to mesh extraction, before space decomposition) are noted.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;code&#34;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Source code will be released soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Optimizing Global Injectivity for Constrained Parameterization</title>
      <link>https://duxingyi-charles.github.io/publication/optimizing-global-injectivity-for-constrained-parameterization/</link>
      <pubDate>Sat, 18 Sep 2021 17:23:54 -0500</pubDate>
      <guid>https://duxingyi-charles.github.io/publication/optimizing-global-injectivity-for-constrained-parameterization/</guid>
      <description>














&lt;figure id=&#34;figure-figure-1-given-a-non-injective-initial-parameterization-of-a-surface-mesh-left-with-inverted-triangles-red-boundary-intersections-orange-dots-and-overwound-vertices-magenta-dots-our-method-recovers-a-globally-injective-map-right-while-keeping-the-constraints-blue-points-in-place-the-inserts-zoom-in-on-one-region-in-the-initial-map-with-many-boundary-intersections-and-inverted-triangles-green-box-and-another-region-with-an-overwound-vertex-cyan-box&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/SEA/fig1.jpeg&#34; data-caption=&#34;Figure 1. Given a non-injective initial parameterization of a surface mesh (left) with inverted triangles (red), boundary intersections (orange dots), and overwound vertices (magenta dots), our method recovers a globally injective map (right) while keeping the constraints (blue points) in place. The inserts zoom in on one region in the initial map with many boundary intersections and inverted triangles (green box) and another region with an overwound vertex (cyan box).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/SEA/fig1.jpeg&#34; alt=&#34;featured&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1. Given a non-injective initial parameterization of a surface mesh (left) with inverted triangles (red), boundary intersections (orange dots), and overwound vertices (magenta dots), our method recovers a globally injective map (right) while keeping the constraints (blue points) in place. The inserts zoom in on one region in the initial map with many boundary intersections and inverted triangles (green box) and another region with an overwound vertex (cyan box).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;abstract&#34;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Injective parameterizations of triangulated meshes are critical across applications but remain challenging to compute. Existing algorithms to find injectivity either require initialization from an injective starting state, which is currently only possible without positional constraints, or else can only prevent triangle inversion, which is insufficient to ensure injectivity. Here we present, to our knowledge, the first algorithm for recovering a globally injective parameterization from an arbitrary non-injective initial mesh subject to stationary constraints. These initial meshes can be inverted, wound about interior vertices and/or overlapping. Our algorithm in turn enables globally injective mapping for meshes with arbitrary positional constraints. Our key contribution is a new energy, called smooth excess area (SEA), that measures non-injectivity in a map. This energy is well-defined across both injective and non-injective maps and is smooth almost everywhere, making it readily minimizable using standard gradient-based solvers starting from a non-injective initial state. Importantly, we show that maps minimizing SEA are guaranteed to be locally injective and almost globally injective, in the sense that the overlapping area can be made arbitrarily small. Analyzing SEA’s behavior over a new benchmark set designed to test injective mapping, we find that optimizing SEA successfully recovers globally injective maps for 85% of the benchmark and obtains locally injective maps for 90%. In contrast, state-of-the-art methods for removing triangle inversion obtain locally injective maps for less than 6% of the benchmark, and achieve global injectivity (largely by chance as prior methods are not designed to recover it) on less than 4%.&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;fast-forward&#34;&gt;&lt;strong&gt;Fast Forward&lt;/strong&gt;&lt;/h3&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/XvewOf-U7Gw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;summary&#34;&gt;&lt;strong&gt;Summary&lt;/strong&gt;&lt;/h3&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/STFiyq2iAmQ&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;presentation&#34;&gt;&lt;strong&gt;Presentation&lt;/strong&gt;&lt;/h3&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/RCNbyUOlav0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;optimization-process&#34;&gt;&lt;strong&gt;Optimization Process&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The process of optimizing SEA (smooth excess area) on the examples presented in the paper.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/JXtlrBec4Rs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;dataset&#34;&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We create a benchmark dataset for evaluating various methods&amp;rsquo; capability to recover an injective mapping from a non-injective initial mapping while keeping a group of positional constraints in place.&lt;/p&gt;
&lt;p&gt;The dataset includes 1791 triangular mesh examples. Each example contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;input.obj&lt;/code&gt;: rest mesh and initial mesh (as UV coordinates)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;handles.txt&lt;/code&gt;: list of indices of the fixed vertices&lt;/li&gt;
&lt;li&gt;&lt;code&gt;groundTruth.obj&lt;/code&gt;: globally injective mesh satisfying positional constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also provide the result of our method for each example.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://doi.org/10.5281/zenodo.5547887&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;Download Dataset&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Source code is hosted on 
&lt;a href=&#34;https://github.com/duxingyi-charles/Smooth-Excess-Area&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;figures&#34;&gt;&lt;strong&gt;Figures&lt;/strong&gt;&lt;/h2&gt;















&lt;figure id=&#34;figure-figure-2-three-successful-examples-from-the-benchmark-initial-maps-first-column-maps-produced-by-our-method-second-column-which-are-all-globally-injective-and-maps-produced-by-lbd-third-column-and-sa-last-column-none-of-which-are-locally-or-globally-injective&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/SEA/fig-success.png&#34; data-caption=&#34;Figure 2. Three successful examples from the benchmark: initial maps (first column), maps produced by our method (second column), which are all globally injective, and maps produced by LBD (third column) and SA (last column), none of which are locally or globally injective.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/SEA/fig-success.png&#34; alt=&#34;fig-success&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 2. Three successful examples from the benchmark: initial maps (first column), maps produced by our method (second column), which are all globally injective, and maps produced by LBD (third column) and SA (last column), none of which are locally or globally injective.
  &lt;/figcaption&gt;


&lt;/figure&gt;
















&lt;figure id=&#34;figure-figure-3-from-left-to-right-input-meshes-with-one-or-two-boundaries-non-injective-initial-maps-globally-injective-maps-produced-by-our-method-sea-and-results-of-lbd-and-sa-both-lbd-and-sa-have-removed-most-or-all-inverted-triangles-but-the-results-are-neither-locally-or-globally-injective-due-to-overwound-vertices-and-boundary-intersections&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/SEA/fig-toys.png&#34; data-caption=&#34;Figure 3. From left to right: input meshes (with one or two boundaries), non-injective initial maps, globally injective maps produced by our method (SEA), and results of LBD and SA. Both LBD and SA have removed most or all inverted triangles, but the results are neither locally or globally injective due to overwound vertices and boundary intersections.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/SEA/fig-toys.png&#34; alt=&#34;fig-toys&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 3. From left to right: input meshes (with one or two boundaries), non-injective initial maps, globally injective maps produced by our method (SEA), and results of LBD and SA. Both LBD and SA have removed most or all inverted triangles, but the results are neither locally or globally injective due to overwound vertices and boundary intersections.
  &lt;/figcaption&gt;


&lt;/figure&gt;
















&lt;figure id=&#34;figure-figure-4-two-initial-maps-with-overwound-vertices-top-and-the-injective-maps-produced-by-our-method-bottom&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/SEA/fig-overwound-1-rings.png&#34; data-caption=&#34;Figure 4. Two initial maps with overwound vertices (top) and the injective maps produced by our method (bottom).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/SEA/fig-overwound-1-rings.png&#34; alt=&#34;fig-overwound-1-rings&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 4. Two initial maps with overwound vertices (top) and the injective maps produced by our method (bottom).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;!-- ### **Acknowledgments**

This work is supported in part by NSF grant RI-1618685, NIH grant U2C CA233303-1, and Simons Math+X Investigators Award 400837. We would like to thank authors of several papers for providing code, data, and help with comparisons, and especially Hanxiao Shen, Ofir Weber, Alon Bright, Zohar Levi, and Xiao-Ming Fu. --&gt;
</description>
    </item>
    
    <item>
      <title>Boundary-Sampled Halfspaces: A New Representation for Constructive Solid Modeling</title>
      <link>https://duxingyi-charles.github.io/publication/boundary-sampled-halfspaces/</link>
      <pubDate>Fri, 21 May 2021 17:23:54 -0500</pubDate>
      <guid>https://duxingyi-charles.github.io/publication/boundary-sampled-halfspaces/</guid>
      <description>














&lt;figure id=&#34;figure-figure-1-a-segmented-shape-a-is-converted-into-our-representation-b-which-consists-of-halfspaces-associated-with-sparse-samples-colored-spheres-each-halfspace-is-either-a-simple-primitive-eg-plane-sphere-etc-or-a-free-form-implicit-surface-one-is-shown-in-transparency-the-representation-can-be-easily-edited-by-modifying-the-halfspaces-andor-their-samples-c&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/BSH/fig1.png&#34; data-caption=&#34;Figure 1. A segmented shape (a) is converted into our representation (b), which consists of halfspaces associated with sparse samples (colored spheres). Each halfspace is either a simple primitive (e.g., plane, sphere, etc.) or a free-form implicit surface (one is shown in transparency). The representation can be easily edited by modifying the halfspaces and/or their samples (c).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/BSH/fig1.png&#34; alt=&#34;featured&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1. A segmented shape (a) is converted into our representation (b), which consists of halfspaces associated with sparse samples (colored spheres). Each halfspace is either a simple primitive (e.g., plane, sphere, etc.) or a free-form implicit surface (one is shown in transparency). The representation can be easily edited by modifying the halfspaces and/or their samples (c).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;abstract&#34;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We present a novel representation of solid models for shape design. Like Constructive Solid Geometry (CSG), the solid shape is constructed from a set of halfspaces without the need for an explicit boundary structure. Instead of using Boolean expressions as in CSG, the shape is defined by sparsely placed samples on the boundary of each halfspace. This representation, called Boundary-Sampled Halfspaces (BSH), affords greater agility and expressiveness than CSG while simplifying the reverse engineering process. We discuss theoretical properties of the representation and present practical algorithms for boundary extraction and conversion from other representations. Our algorithms are demonstrated on both 2D and 3D examples.&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;fast-forward&#34;&gt;Fast Forward&lt;/h4&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ujd4t9skJ_Y&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h4 id=&#34;quick-summary&#34;&gt;Quick Summary&lt;/h4&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rCKh39pEdrg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h4 id=&#34;full-presentation&#34;&gt;Full Presentation&lt;/h4&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/-lKQAQhfX3I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h4 id=&#34;software-demo&#34;&gt;Software Demo&lt;/h4&gt;
&lt;p&gt;We demonstrate the modeling process of various examples using Boundary-Sampled Halfspaces.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BRO36bIMXxI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;2d-shape-design&#34;&gt;&lt;strong&gt;2D Shape Design&lt;/strong&gt;&lt;/h2&gt;















&lt;figure id=&#34;figure-figure-2-several-2d-shapes-modeled-by-bsh-halfspaces-for-the-last-two-shapes-are-not-shown-due-to-their-complexity&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/BSH/fig-gallery-2D.png&#34; data-caption=&#34;Figure 2. Several 2D shapes modeled by BSH. Halfspaces for the last two shapes are not shown due to their complexity.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/BSH/fig-gallery-2D.png&#34; alt=&#34;fig-gallery-2D&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 2. Several 2D shapes modeled by BSH. Halfspaces for the last two shapes are not shown due to their complexity.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;3d-shape-design&#34;&gt;&lt;strong&gt;3D Shape Design&lt;/strong&gt;&lt;/h2&gt;















&lt;figure id=&#34;figure-figure-3-various-bsh-shapes-created-from-one-torus-and-several-spheres-by-choosing-which-segment-of-the-torus-has-a-sample-different-segments-can-be-kept-or-deleted-while-the-shape-remains-a-solid&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/BSH/fig-beads.png&#34; data-caption=&#34;Figure 3. Various BSH shapes created from one torus and several spheres. By choosing which segment of the torus has a sample, different segments can be kept or deleted while the shape remains a solid.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/BSH/fig-beads.png&#34; alt=&#34;fig-beads&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 3. Various BSH shapes created from one torus and several spheres. By choosing which segment of the torus has a sample, different segments can be kept or deleted while the shape remains a solid.
  &lt;/figcaption&gt;


&lt;/figure&gt;
















&lt;figure id=&#34;figure-figure-4-shape-modeled-by-bsh-that-cannot-be-represented-by-csg-without-additional-halfspaces-for-the-first-two-shapes-input-halfspaces-are-on-the-left-and-the-final-shapes-are-on-the-right-the-last-shape-heart-is-shown-in-two-views-and-the-second-view-shows-a-halfspace-represented-as-a-vipss-implicit-surface-interpolating-a-sparse-set-of-control-points-red-spheres&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/BSH/fig-gallery-3D.png&#34; data-caption=&#34;Figure 4. Shape modeled by BSH that cannot be represented by CSG without additional halfspaces. For the first two shapes, input halfspaces are on the left and the final shapes are on the right. The last shape (“Heart”) is shown in two views, and the second view shows a halfspace represented as a VIPSS implicit surface interpolating a sparse set of control points (red spheres).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/BSH/fig-gallery-3D.png&#34; alt=&#34;fig-gallery-3D&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 4. Shape modeled by BSH that cannot be represented by CSG without additional halfspaces. For the first two shapes, input halfspaces are on the left and the final shapes are on the right. The last shape (“Heart”) is shown in two views, and the second view shows a halfspace represented as a VIPSS implicit surface interpolating a sparse set of control points (red spheres).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;converted-from-other-representations&#34;&gt;&lt;strong&gt;Converted from other representations&lt;/strong&gt;&lt;/h2&gt;















&lt;figure id=&#34;figure-figure-5-free-form-bsh-shapes-elk-flower-boat-and-chair-converted-from-meshes-and-undergone-editing-of-the-halfspaces-andor-their-samples-top-each-row-shows-the-input-segmented-mesh-the-converted-bsh-and-result-after-editing-selected-halfspaces-before-and-after-editing-are-shown-with-transparency-bottom-each-row-shows-the-converted-bsh-and-two-editing-results&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/BSH/fig-gallery-reverse.png&#34; data-caption=&#34;Figure 5. Free-form BSH shapes (Elk, Flower, Boat, and Chair) converted from meshes and undergone editing of the halfspaces and/or their samples. Top: each row shows the input segmented mesh, the converted BSH, and result after editing. Selected halfspaces before and after editing are shown with transparency. Bottom: each row shows the converted BSH and two editing results.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/BSH/fig-gallery-reverse.png&#34; alt=&#34;fig-gallery-reverse&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 5. Free-form BSH shapes (Elk, Flower, Boat, and Chair) converted from meshes and undergone editing of the halfspaces and/or their samples. Top: each row shows the input segmented mesh, the converted BSH, and result after editing. Selected halfspaces before and after editing are shown with transparency. Bottom: each row shows the converted BSH and two editing results.
  &lt;/figcaption&gt;


&lt;/figure&gt;
















&lt;figure id=&#34;figure-figure-6-a-cad-mesh-segmented-and-fitted-by-primitives-a-showing-two-views-the-converted-bsh-shape-b-showing-two-views-and-two-edited-shapes-with-altered-structure-eg-fewer-rings-and-a-missing-shelf-c-and-modified-primitive-geometry-d&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/BSH/fig-cad.png&#34; data-caption=&#34;Figure 6. A CAD mesh segmented and fitted by primitives (a; showing two views), the converted BSH shape (b; showing two views), and two edited shapes with altered structure (e.g., fewer rings and a missing shelf) (c) and modified primitive geometry (d).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/BSH/fig-cad.png&#34; alt=&#34;fig-cad&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 6. A CAD mesh segmented and fitted by primitives (a; showing two views), the converted BSH shape (b; showing two views), and two edited shapes with altered structure (e.g., fewer rings and a missing shelf) (c) and modified primitive geometry (d).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;!-- ### **Acknowledgments**

This work is supported in part by NSF grant RI-1618685, NIH grant U2C CA233303-1, and Simons Math+X Investigators Award 400837. We would like to thank authors of several papers for providing code, data, and help with comparisons, and especially Hanxiao Shen, Ofir Weber, Alon Bright, Zohar Levi, and Xiao-Ming Fu. --&gt;
</description>
    </item>
    
    <item>
      <title>如何顺利通过 PhD Oral Exam</title>
      <link>https://duxingyi-charles.github.io/post/phd_oral_summary/</link>
      <pubDate>Tue, 30 Jun 2020 22:00:58 -0500</pubDate>
      <guid>https://duxingyi-charles.github.io/post/phd_oral_summary/</guid>
      <description>&lt;p&gt;上个月最后一个周五下午，我坐在电脑前，望着zoom的空白窗口，心里一块大石头高高悬着。在屏幕那一边，三位教授正讨论着。几分钟后，当我听到教授说出“congrats”时，心里的石头终于落地，我终于通过了口试。&lt;/p&gt;
&lt;p&gt;口试，全称 PhD oral qualifying exam，是我系博士生确定导师后的第一个重要关口。过了这一关，离毕业就近了一步。而如果第五学期还没有通过口试，则学业受阻。&lt;/p&gt;
&lt;p&gt;这已是我博士的第四个学期，口试自然是我的心头大事。回想准备口试的这段时间，一个个场景还历历在目，发邮件邀请教授时的纠结，面对天书似的论文时的烦躁，制作ppt时的手足无措，口试前夕分秒必争的紧张。为了督促自己，我曾每日清晨在小白板上写下口试倒计时天数，一如当年的高考，却每每在天黑时顿觉进展缓慢。&lt;/p&gt;
&lt;p&gt;回头来看，多少烦恼，多少彷徨，皆因缺乏经验，不知前进的方向，缺乏方法，每每误入歧途。因此，我想回顾自己准备口试的经过，总结其中的经验教训，既提醒未来的自己，也希望能帮助其他同学更顺利地通过口试。&lt;/p&gt;
&lt;p&gt;口试的准备经历了邀请教授，读论文与选论文，准备报告这3个阶段。下面逐一总结。&lt;/p&gt;
&lt;h2 id=&#34;邀请教授&#34;&gt;邀请教授&lt;/h2&gt;
&lt;p&gt;今年3月初，和导师聊了口试的打算。当时，我们正好要开始一个新的科研项目，于是导师建议我通过准备口试，阅读文献，熟悉这个研究领域。&lt;/p&gt;
&lt;p&gt;确定了口试主题，接下来就是邀请三位教授了。和导师商量后，三位教授的人选确定下来。其中两位是与我们研究方向相近的老师，第三位是出于“礼尚往来”，因为导师曾参加过几次这位教授学生的口试。&lt;/p&gt;
&lt;p&gt;接下来就是发邮件邀请教授了。当时，我没有立即发出邀请，主要是我对于新的研究领域所知甚少，更没有选定三篇论文，于是不知怎么写这封邮件，担心教授们会不会追问更多细节。&lt;/p&gt;
&lt;p&gt;现在看来，这种担心是毫无必要的，因为这封邮件的主要目的是约定口试时间，而非讨论口试内容。站在教授的角度上看，比起口试所讲具体内容，他们更关心学生读论文和讲论文的能力。&lt;/p&gt;
&lt;p&gt;于是，三月中旬，我向实验室学长请教了邮件的写法后，发出了邀请。考虑到学期中上课和科研的压力，我希望把时间定在期末考试后的五月中下旬。邮件里，我询问了教授们这个时间段是否合适，关于口试内容，仅仅提及了大概的研究领域。&lt;/p&gt;
&lt;p&gt;邮件发出后，教授们很快就回复了。大家一致同意在五月末进行口试。然后，我用
&lt;a href=&#34;http://whenisgood.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;whenisgood&lt;/a&gt;设置了一些具体时间段（每段两个小时），供教授们选择。 最后，口试定在了五月最后一个周五的下午。&lt;/p&gt;
&lt;h2 id=&#34;读论文与选论文&#34;&gt;读论文与选论文&lt;/h2&gt;
&lt;p&gt;确定了口试时间，接下来就是找论文，读论文，并从中选三篇用作口试。&lt;/p&gt;
&lt;p&gt;在找论文这件事上，导师帮助良多。三月初，导师写了一份新项目的研究计划，其中搜集了两个相关研究方向的约10篇论文。我的口试论文从中选三篇即可。关于找论文，我还听到学长的经验，即从一篇近期论文出发，沿着相关工作和引用文献向前追溯该领域的经典之作。这里推荐一个我常用的文献搜索引擎
&lt;a href=&#34;https://www.semanticscholar.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Semantic scholar&lt;/a&gt;。它可以自动分析参考文献，推荐相关论文。这对于找论文是很实用的功能。&lt;/p&gt;
&lt;p&gt;论文大致范围框定后，我通过6个步骤，一边缩小论文范围，一边加深对论文的理解。3篇论文的选择在这个过程中也渐渐清晰起来。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;了解背景&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了建立对研究领域的整体认识，避免陷入“盲人摸象”的误区，我没有直接去阅读那10篇论文，而是先花四五天时间给自己科普了一下该研究领域。这一步是为了了解整个领域的主要问题和挑战，体会研究意义（即为什么要研究这个问题）。&lt;/p&gt;
&lt;p&gt;科普的具体方法就是浏览各式资料（wiki，课件，视频，博客，教科书等）。不同资料可以提供不同的角度。不同形式的资料也各具特点，比如课件较简洁，视频很直观，而教科书最为系统。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;提取要旨&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这一步，我迅速把10篇论文浏览一遍，基本只读论文的导言和结论部分，提取每篇论文的要旨，即论文解决了什么问题（输入，输出，基本假设），用了什么方法，解决问题的效果如何。&lt;/p&gt;
&lt;p&gt;过程中难免会遇到一些暂时不理解的概念，这时不必深究，记录下关键词即可。&lt;/p&gt;
&lt;p&gt;通过这个过程，我对这些论文不再感到陌生。而且，通过阅读不同论文的导言，从多个角度增进了对该领域的了解。&lt;/p&gt;
&lt;p&gt;这时，根据对研究主题的把握，综合考虑个人兴趣和论文易读性，我在两个子方向中选择一个继续深入。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;细读论文&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然上一步提取了论文要旨，但由于其过程“不求甚解”，我对这些论文仍感到“似懂非懂”。为了获得更深的理解，我选取一篇论文，深入阅读，力图把它的思想和方法吃透。&lt;/p&gt;
&lt;p&gt;作为第一篇细读的论文，不妨挑剔些，最好能兼顾几条标准：顶会发表，高影响力，自己感兴趣，读着通顺，近期发表。前两条保证了所选论文的质量。中间两条让自己读起来相对轻松。最后，近期发表的文章会总结评价更早之前的论文，为之后选论文提供参考。&lt;/p&gt;
&lt;p&gt;对于细读的论文，我会边读边做笔记。当遇到晦涩的论文，读不下去时，做笔记有助于平和心气，一点点读懂论文。另一方面，相比论文，笔记更简洁，条理更清晰，方便反复查阅。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;回顾与分类&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有了吃透一篇论文的基础，再去浏览一遍其他论文，或许会发现，有些之前不理解的概念，现在大概明白它的意思了。这时，可以根据新的理解对之前记录的论文要旨进行补充修正。&lt;/p&gt;
&lt;p&gt;在此基础上，可以进一步考虑能否对论文进行分类。如果这时发现，论文已经自然地分成几类，就可以从每类中选出一篇，作为口试论文，进一步细读。如果分类还不清晰，可以返回第三步，再挑一篇论文细读，加深理解。&lt;/p&gt;
&lt;p&gt;如此重复，三篇论文的选择最终会变得清晰，论文内容也在这一过程中逐渐掌握。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;归纳整理&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有些内容虽然分散在不同论文中，但解答的是同一个问题，例如研究意义，面临的挑战等。这些内容在之后讲论文时必须归在一处。这一步就是要把这些相似的内容整理出来。首先，从不同论文中收集相似内容，然后，进一步梳理内容之间的联系，使其更有条理。&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;融汇贯通&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过上面5步，三篇论文各自的方法和结果，论文之间共通的部分（如研究意义，困难挑战），都在我们掌握之中了。然而，要形成一场连贯的口试报告，这些内容不能是割裂的，而要浑然一体。这一步，就是要思考不同内容的联系，构建这个整体。&lt;/p&gt;
&lt;p&gt;除去共通的研究背景，三篇论文的主要内容无非各自的方法和结果，这也是比较容易显得分立的部分。因此，所谓“融汇贯通”，主要是把三种方法统一到一个框架下。这个框架应该帮助我们比较和分析三种方法。最主要的是回答一个问题，如何从方法的不同解释不同论文结果的差异。这个问题的答案，有助于揭示论文方法的背后的设计思想，也有助于提出未来的研究方向。&lt;/p&gt;
&lt;p&gt;要解答这个问题，可以先把三篇论文结果的对比整理成一张表，然后梳理论文的方法，分析其异同，最后尝试解释这些不同点如何造成结果的差异。&lt;/p&gt;
&lt;h2 id=&#34;准备报告&#34;&gt;准备报告&lt;/h2&gt;
&lt;p&gt;通过论文的阅读和总结，口试的内容素材就准备齐全了，接下来的任务是把素材组织成35分钟的口试报告。由于口试时间的限制，不可能讲完论文的所有内容，因此需要思考“讲什么”，甄选素材，突出重点，把关键信息传达给听众。口试报告的另一个难点在于，听众可能来自完全不同的研究领域，对口试主题一无所知。因此，选取恰当的表现方式，力图听众能够顺畅地理解，也是准备报告时必须解决的问题。&lt;/p&gt;
&lt;p&gt;说实话，准备演讲报告实在是一个过于庞大的话题。这里，我只想谈谈在这次口试准备中，自己走过的弯路和收获的经验。&lt;/p&gt;
&lt;h3 id=&#34;讲什么&#34;&gt;讲什么&lt;/h3&gt;
&lt;p&gt;“提出问题”，“分析问题”，“解决问题”是口试报告的主体内容。“提出问题”这部分，需要让听众理解这项研究解决了一个什么问题，以及为什么解决这个问题是重要的。“分析问题”，则需要讲清楚这个问题为什么难以解决。最后，“解决问题”要阐述三篇论文用了什么样的方法解决这个问题，最终效果如何。&lt;/p&gt;
&lt;p&gt;“提出问题”，“分析问题”这两部分虽然不是三篇论文的主要贡献，但若听众不理解这两部分，就无从鉴赏“解决问题”的方法，仿佛会议中途才入场的与会者，抓不住主题，摸不着头脑。其次，作为报告的开头，这两部分往往也是新概念，新术语集中涌现的地方。因此，这两部分完全值得放慢节奏，花时间细讲，以确保听众准确理解。此外，最好还能调动听众的兴趣，让他们期待后面论文的内容。&lt;/p&gt;
&lt;p&gt;三篇论文中最庞杂的内容就是“解决问题”的方法。因此，控制报告的时间，要从精简“解决问题”这部分入手。在这方面，我刚开始准备报告的时候也没有把握好，基本上直接把论文的方法部分稍微整理一下，照搬到ppt上，导致报告内容繁杂，严重超时。&lt;/p&gt;
&lt;p&gt;后来，在导师的点拨下，我才明白只需把论文方法最核心的思想讲清楚。在保证核心内容的基础上，根据报告时间调整其它内容的详略，对于一些细节，可以一带而过，甚至不需要提及。&lt;/p&gt;
&lt;p&gt;要抓住一篇论文的核心思想，可以尝试用一句话概括论文。这句话里不能舍弃的内容，就是这篇论文的核心，也就是讲解的重点。另外，论文本身的摘要是作者自己对论文内容的精炼，自然也可以在其中寻找论文的核心思想。&lt;/p&gt;
&lt;p&gt;对于熟读论文的我们，一句话或许足以概括论文的核心思想，但对于缺乏背景知识的听众，恐怕仍然会觉得一头雾水。因此，接下来的工作，就是站在听众的角度，思考要让听众理解这个核心思想，需要铺垫哪些基础，提供什么具体例子。最后，根据这些思考逐步把核心思想扩展成完整的报告。&lt;/p&gt;
&lt;p&gt;上面讲了哪些内容需要细讲，下面说说哪些内容可以略讲甚至不讲。简单来说，相对于核心内容的“不可替代”，可以略讲的就是论文方法中那些“可替代性”高的内容。例如，论文套用前人方法解决一个子问题，或者一个临时想出来的启发式方法。这些内容即使换成其它方法也不会影响论文的创新性，因此不是论文的核心。此外，由于看问题的角度不同，论文中可能包含一些和口试主题关联不紧密的内容，这些也可以略过。&lt;/p&gt;
&lt;p&gt;最后，如果自己对于内容的取舍没有十足的把握，不妨把相对次要的内容放在 ppt 的 hidden slides 中，以备教授的提问。&lt;/p&gt;
&lt;h3 id=&#34;怎么讲&#34;&gt;怎么讲&lt;/h3&gt;
&lt;p&gt;“怎么讲”是一个内容丰富的话题，这里只谈谈我在准备报告过程中发现的几个容易忽视，从而造成听众理解困难的事项。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不要假设听众有相关背景知识&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于那些不算学科常识的概念，都不能假设听众熟悉。在第一次提及这些陌生概念时，必须给出充分的解释。尤其在报告开头部分，为了引入研究问题，势必提出大量新概念，这时要有意识地放慢节奏，确保听众有时间消化理解。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;避免信息过载&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;听众接收信息的速度是有限的，如果大量信息扑面而来，人往往会错失一些重要信息。解决办法是拆分。如果一页ppt内容太多，可以拆成多页来讲。把静态的信息做成动画，也是拆分的有效手段。动画可以使听众把注意力放在最新出现的内容上，从而减轻信息处理的负担。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;使用形象化的呈现方式&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;人脑对文字，符号，公式，复杂图表等抽象信息的处理速度是较慢的。在快节奏的报告中，听众往往没时间理解这些内容。因此，应使用图片，动画，视频等形式使抽象信息变得形象生动起来。对于抽象概念，应举出具体例子说明。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;使用总分结构&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有时，听众会因缺乏整体图景而感到困惑。因此，我们需要提供一张全局地图。使用先总后分的结构呈现内容，在深入讲解之前，先进行简短的概括和预告。这样，面对后面的细节内容，观众已经有了心理准备，了解其背景和目的，就不至于对所讲内容感到迷茫。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;避免跳跃，增加连贯性&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在内容上，为便于听众理解，应注意加强前后部分的连贯性。在ppt制作上，应减少视觉跳跃，可以使用动画承接，或适当使用转场过渡。&lt;/p&gt;
&lt;h3 id=&#34;制作ppt&#34;&gt;制作ppt&lt;/h3&gt;
&lt;p&gt;与“讲什么”和“怎么讲”一样，ppt的制作也足以花一整本书的篇幅去讲。这里我要讲的不是如何让ppt显得专业美观，而是当我们有了关于报告内容的大体想法后，如何通过一个可操作的流程，把想法落实，制作出第一版的ppt。相较于“从有到好”，这里更关注的是“从无到有”的过程。&lt;/p&gt;
&lt;p&gt;在我的经验中，“从无到有”是一个充满纠结的过程。“无”意味着一张白纸，它似乎留给我们无限的可能性，却也没有指出任何明确的前进方向。就像人生的路一样，在“从无到有”的过程中，我们需要不断地做出选择。然而，面对前方的未知和尚不清晰的整体，我们往往会怀疑当下的选择，总是惦念着那“未选择的路”。更糟糕的是，有时候我花了很多时间雕琢ppt细节，却在某刻突然意识到，应该使用一种完全不同的讲法，于是只能推倒重来，浪费了许多时间。&lt;/p&gt;
&lt;p&gt;这样的苦头吃多了，我意识到自己缺乏的是一个合理的流程，也就是正确的做事顺序。在做ppt这件事上，不应该一上来就扑到一页页ppt上，而应该从高向低逐层规划，当上一层设计经过反复推敲已经定型后，再深入到下一层。对于口试报告，最高层已经确定为“提出问题”，“分析问题”，“解决问题”三大块，从此往下还有三个层次。最上层是报告的核心思想，中间一层是为阐述核心思想而展开的内容，最低一层才是这些内容的具体呈现，即ppt上看到的东西。如果顶层设计还没有想清楚，就开始着手最底层的呈现，就难免会走冤枉路，白费精力。&lt;/p&gt;
&lt;p&gt;具体来说，核心思想和展开内容这两层，可以做成一个提纲，按顺序列出要点。这里要注意，当几条要点并列时，要仔细思考它们之间的联系，考虑能否合并，或者是否有递进和依赖关系，需要按照一定的顺序讲出。&lt;/p&gt;
&lt;p&gt;最后，从内容要点到ppt呈现，中间还可以加一个草图层。这一步，可以先在草稿纸上涂画ppt的大致构图。这样，我们可以把格式细节问题放在一边，专注于快速灵活地探索设计。&lt;/p&gt;
&lt;h3 id=&#34;他人的反馈&#34;&gt;他人的反馈&lt;/h3&gt;
&lt;p&gt;由于我们对所讲内容太过熟悉，往往不能完全站在听众的角度审视，因此，他人的反馈在准备报告的过程中十分重要。&lt;/p&gt;
&lt;p&gt;当做出一个基本成型的ppt后，就可以讲给他人，寻求反馈了。这件事宜早不宜迟， 因为通过他人的反馈，往往会发现还有许多要修改的地方。&lt;/p&gt;
&lt;p&gt;我在准备报告中主要有两次反馈。第一次是导师，时间在第一版ppt制作完成后。这次反馈主要针对报告的结构和内容。在吸纳导师意见，修改ppt后，我找到几个同学进行模拟排练。这次就不仅是针对内容，还要按照口试要求的时间去讲。这次排练帮我适应了口试的节奏和气氛，从而在实际口试中就不会感到特别紧张了。这些同学最好是已经通过口试的过来人，并能提出批判性的建议。如果论文涉及自己不熟悉的领域，也可以找相关领域的同学给自己把关。&lt;/p&gt;
&lt;h2 id=&#34;写在最后&#34;&gt;写在最后&lt;/h2&gt;
&lt;p&gt;考试已过去一个月了，六月的最后一天在一场大雨中落幕。这个不寻常的年份即将过半，而往日生活的热闹似乎也在一点点恢复。感谢最初在闲聊中提出写作这篇总结想法的朋友，也感谢其他同学的鼓励，如果没有你们，我恐怕不会有机会如此认真地思考这段经历。许多心得，也只有在写作的反复斟酌中，才渐渐清晰起来。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lifting Simplices to Find Injectivity</title>
      <link>https://duxingyi-charles.github.io/publication/lifting-simplices-to-find-injectivity/</link>
      <pubDate>Mon, 04 May 2020 17:23:54 -0500</pubDate>
      <guid>https://duxingyi-charles.github.io/publication/lifting-simplices-to-find-injectivity/</guid>
      <description>














&lt;figure id=&#34;figure-figure-1-injectively-mapping-a-complex-surface-mesh-lucy-48k-vertices-to-a-non-convex-boundary-letter-g-with-zoom-ins-on-the-left-and-mapping-a-tetrahedral-mesh-armadillo-6k-vertices-to-a-highly-deformed-target-surface-on-the-right-as-a-result-of-minimizing-our-novel-energy-these-two-examples-are-part-of-our-new-benchmark-data-set&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/TLC/fig1.png&#34; data-caption=&#34;Figure 1. Injectively mapping a complex surface mesh (Lucy, 48K vertices) to a non-convex boundary (letter “G”, with zoom-ins), on the left, and mapping a tetrahedral mesh (Armadillo, 6K vertices) to a highly deformed target surface, on the right, as a result of minimizing our novel energy. These two examples are part of our new benchmark data set.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/TLC/fig1.png&#34; alt=&#34;fig1&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1. Injectively mapping a complex surface mesh (Lucy, 48K vertices) to a non-convex boundary (letter “G”, with zoom-ins), on the left, and mapping a tetrahedral mesh (Armadillo, 6K vertices) to a highly deformed target surface, on the right, as a result of minimizing our novel energy. These two examples are part of our new benchmark data set.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;abstract&#34;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Mapping a source mesh into a target domain while preserving local injectivity is an important but highly non-trivial task. Existing methods either require an already-injective starting configuration, which is often not available, or rely on sophisticated solving schemes. We propose a novel energy form, called Total Lifted Content (&lt;strong&gt;TLC&lt;/strong&gt;), that is equipped with theoretical properties desirable for injectivity optimization. By lifting the simplices of the mesh into a higher dimension and measuring their contents (2D area or 3D volume) there, &lt;strong&gt;TLC&lt;/strong&gt; is smooth over the entire embedding space and its global minima are always injective. The energy is simple to minimize using standard gradient-based solvers. Our method achieved &lt;em&gt;100&lt;/em&gt;% success rate on an extensive benchmark of embedding problems for triangular and tetrahedral meshes, on which existing methods only have varied success.&lt;/p&gt;
&lt;h3 id=&#34;video&#34;&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/h3&gt;












  


&lt;video controls &gt;
  &lt;source src=&#34;fast_forward.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;h3 id=&#34;dataset&#34;&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We present the large benchmark dataset of 2D/3D meshes used to compare with previous methods. The dataset includes &lt;em&gt;10743&lt;/em&gt; triangular mesh examples and &lt;em&gt;904&lt;/em&gt; tetrahedral mesh examples. The dataset is divided into 3 categories, 2D parameterization, 3D parameterization and 3D deformation.&lt;/p&gt;
&lt;h4 id=&#34;2d-parameterization&#34;&gt;2D Parameterization&lt;/h4&gt;















&lt;figure id=&#34;figure-figure-2-four-examples-in-the-2d-parameterization-category-derived-from-liu-et-al-2018-where-methods-ff-and-lbd-failed-to-find-injective-embeddings-inverted-triangles-are-colored-in-red-and-the-numbers-of-inversion-are-marked-in-red&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/TLC/2D-Param.png&#34; data-caption=&#34;Figure 2. Four examples in the 2D parameterization category derived from [Liu et al. 2018], where methods FF and LBD failed to find injective embeddings. Inverted triangles are colored in red, and the numbers of inversion are marked in red.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/TLC/2D-Param.png&#34; alt=&#34;2D Parameterization&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 2. Four examples in the 2D parameterization category derived from [Liu et al. 2018], where methods FF and LBD failed to find injective embeddings. Inverted triangles are colored in red, and the numbers of inversion are marked in red.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;3d-parameterization&#34;&gt;3D Parameterization&lt;/h4&gt;















&lt;figure id=&#34;figure-figure-3-three-examples-from-the-3d-parameterization-category-each-mapping-a-rest-tetrahedral-mesh-into-a-sphere-top-smooth-surface-middle-and-a-polycube-bottom-each-example-is-a-failure-case-for-one-of-the-three-methods-ff-lbd-and-sa-inverted-tetrahedra-are-colored-in-red-and-the-numbers-of-inversion-are-marked-in-red&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/TLC/3D-Param.png&#34; data-caption=&#34;Figure 3. Three examples from the 3D parameterization category, each mapping a rest tetrahedral mesh into a sphere (top), smooth surface (middle), and a polycube (bottom). Each example is a failure case for one of the three methods, FF, LBD and SA. Inverted tetrahedra are colored in red, and the numbers of inversion are marked in red.&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/TLC/3D-Param.png&#34; alt=&#34;3D Parameterization&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 3. Three examples from the 3D parameterization category, each mapping a rest tetrahedral mesh into a sphere (top), smooth surface (middle), and a polycube (bottom). Each example is a failure case for one of the three methods, FF, LBD and SA. Inverted tetrahedra are colored in red, and the numbers of inversion are marked in red.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;3d-deformation&#34;&gt;3D Deformation&lt;/h4&gt;















&lt;figure id=&#34;figure-figure-4-three-examples-in-the-3d-deformation-category-a-twisting-armadillo-where-ff-sa-and-lbd-all-failed-to-reach-injectivity-the-graph-in-the-top-right-shows-the-number-of-inverted-tetrahedra-for-each-of-the-600-frames-of-the-deformation-sequence-ellipses-indicate-the-frames-from-which-the-three-examples-were-taken&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/TLC/3D-Deform.png&#34; data-caption=&#34;Figure 4. Three examples in the 3D deformation category (a twisting armadillo) where FF, SA and LBD all failed to reach injectivity. The graph in the top-right shows the number of inverted tetrahedra for each of the 600&amp;#43; frames of the deformation sequence (ellipses indicate the frames from which the three examples were taken).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/TLC/3D-Deform.png&#34; alt=&#34;3D Deformation&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 4. Three examples in the 3D deformation category (a twisting armadillo) where FF, SA and LBD all failed to reach injectivity. The graph in the top-right shows the number of inverted tetrahedra for each of the 600+ frames of the deformation sequence (ellipses indicate the frames from which the three examples were taken).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;dataset-organization&#34;&gt;Dataset Organization&lt;/h4&gt;
&lt;p&gt;Each triangular mesh example contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;input.obj&lt;/code&gt;: rest mesh and initial mesh (as uv coordinates)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;handles.txt&lt;/code&gt;: list of indices of the fixed vertices&lt;/li&gt;
&lt;li&gt;&lt;code&gt;result.obj&lt;/code&gt;: result of our method&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each tetrahedral mesh example contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rest.vtk&lt;/code&gt;: rest mesh&lt;/li&gt;
&lt;li&gt;&lt;code&gt;init.vtk&lt;/code&gt;: initial mesh&lt;/li&gt;
&lt;li&gt;&lt;code&gt;handles.txt&lt;/code&gt;: list of indices of the fixed vertices&lt;/li&gt;
&lt;li&gt;&lt;code&gt;result.vtk&lt;/code&gt;: result of our method&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an introduction to 
&lt;a href=&#34;https://lorensen.github.io/VTKExamples/site/VTKFileFormats/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VTK format&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://doi.org/10.5281/zenodo.3827969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;Download Dataset&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- ### **Acknowledgments**

This work is supported in part by NSF grant RI-1618685, NIH grant U2C CA233303-1, and Simons Math+X Investigators Award 400837. We would like to thank authors of several papers for providing code, data, and help with comparisons, and especially Hanxiao Shen, Ofir Weber, Alon Bright, Zohar Levi, and Xiao-Ming Fu. --&gt;
</description>
    </item>
    
    <item>
      <title>Quad Mesh Generation via Field-Aligned Centroidal Voronoi Tessellation</title>
      <link>https://duxingyi-charles.github.io/publication/quad-mesh-generation-via-field-aligned-centroidal-voronoi-tessellation/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://duxingyi-charles.github.io/publication/quad-mesh-generation-via-field-aligned-centroidal-voronoi-tessellation/</guid>
      <description>














&lt;figure id=&#34;figure-figure-1-given-an-orthogonal-directional-field-left-and-a-triangular-mesh-middle-left-our-method-repositions-mesh-vertices-to-align-with-the-field-direction-middle-right-finally-triangles-are-paired-to-obtain-a-quad-dominant-meshright&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/qfcvt-overview.png&#34; data-caption=&#34;Figure 1. Given an orthogonal directional field (left) and a triangular mesh (middle left), our method repositions mesh vertices to align with the field direction (middle right). Finally, triangles are paired to obtain a quad-dominant mesh(right).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/qfcvt-overview.png&#34; alt=&#34;overview of algorithm&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1. Given an orthogonal directional field (left) and a triangular mesh (middle left), our method repositions mesh vertices to align with the field direction (middle right). Finally, triangles are paired to obtain a quad-dominant mesh(right).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;abstract&#34;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;In order to generate high quality quad mesh, a novel method based on field-aligned centroidal Voronoi tessellation (CVT) is proposed. Target mesh vertices are first uniformly distributed on input mesh surface via CVT optimization. Then, field-aligned CVT is applied to align mesh edges to the underlying direction field. Next, an initial quad mesh is extracted by matching mesh edges and field directions. Meanwhile, singular vertices are detected and eliminated based on topology optimization. Finally, the output quad-dominant mesh is generated by merging adjacent triangle pairs. Experiments show that our method has the ability to generate field-aligned high quality quad-dominant mesh.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Field-Aligned Isotropic Surface Remeshing</title>
      <link>https://duxingyi-charles.github.io/publication/field-aligned-isotropic-surface-remeshing/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://duxingyi-charles.github.io/publication/field-aligned-isotropic-surface-remeshing/</guid>
      <description>














&lt;figure id=&#34;figure-figure-1-given-a-user-defined-directional-field-left-our-method-aligns-mesh-edges-with-the-field-direction-middle-left-the-result-is-a-high-quality-remeshing-with-less-singular-vertices-right&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://duxingyi-charles.github.io/img/fcvt-cylinder.png&#34; data-caption=&#34;Figure 1. Given a user-defined directional field (left), our method aligns mesh edges with the field direction (middle left). The result is a high quality remeshing with less singular vertices (right).&#34;&gt;


  &lt;img src=&#34;https://duxingyi-charles.github.io/img/fcvt-cylinder.png&#34; alt=&#34;overview of algorithm&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1. Given a user-defined directional field (left), our method aligns mesh edges with the field direction (middle left). The result is a high quality remeshing with less singular vertices (right).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;abstract&#34;&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;We present a novel isotropic surface remeshing algorithm that automatically aligns the mesh edges with an underlying directional field. The alignment is achieved by minimizing an energy function that combines both centroidal Voronoi tessellation and the penalty enforced by a six-way rotational symmetry (6-RoSy) field. The CVT term ensures the uniform distribution of thevertices and the high remeshing quality, while the field constraint enforces the directional alignment of the edges. Experimental results show that the proposed approach has the advantages of both isotropic remeshing and field-aligned remeshing. We demonstrate that our algorithm is superior to the representative state-of-the-art approaches in various aspects.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
